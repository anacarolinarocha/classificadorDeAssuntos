{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador de Assuntos\n",
    "\n",
    "#### Por Ana Carolina Pereira Rocha\n",
    "\n",
    "Este projeto foi desenvolvido como um entregável de uma dissertação de Mestrado em Computação Aplicada pela Universidade de Brasilia. O código em questão tem o objetivo de testar vários modelos de aprendizagem de máquina para fazer a classificação do assunto principal de processos judiciais trabalhistas de acordo com assuntos da Tabela Processual Unificada de Assuntos do Conselho Nacional de Justiça e Tribunal Superior do Trabalho. São comparados modelos Naive Bayes (NB) , Support Vector Machine (SVM), Random Forest (RF) e Multi-layer Perceptron (MLP). Todos os algoritmos são testados em 10 combinações diferentes de parâmetros, com validação cruzada de 5 folds. Os textos são testados em sua represetanção no formato TF-IDF, BM25 e LSA com 100 e 250 tópicos.\n",
    "\n",
    "O código em questão executa os seguintes passos:\n",
    "\n",
    "    Busca em uma pasta os arquivos referentes aos documentos\n",
    "    Faz o pré processamento dos textos\n",
    "    Transforma o texto em uma matriz numérica\n",
    "    Analisa o balanceamento dos dados em função do assunto principal\n",
    "    Faz um GridSearch para verificar os melhores parâmetros e a melhor forma de se representar os textos nos algoritmos\n",
    "    Escolhe o melhor modelo de cada algoritmo em função da micro precisão.\n",
    "    Testa o modelo vencedor de cada algoritmo como as diferentes formas de representação do texto\n",
    "    Escolhe a combinação vencedora em função da micro precisão\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Os modelos de classificação foram treinados para reconhecer os assuntos abaixo, sendo todos assuntos do nível 3 da Tabela Processual Unificada:\n",
    "\n",
    "    2583 - Abono\n",
    "    2594 - Adicional\n",
    "    1663 - Adicional Noturno\n",
    "    5272 - Administração Pública\n",
    "    2506 - Ajuda / Tíquete Alimentação\n",
    "    1806 - Alteração Contratual ou das Condições de Trabalho\n",
    "    5280 - Bancários\n",
    "    1767 - Cesta Básica\n",
    "    1783 - Comissão\n",
    "    1690 - Contribuição / Taxa Assistencial\n",
    "    1773 - Contribuição Sindical\n",
    "    1844 - CTPS\n",
    "    1888 - Descontos Salariais - Devolução\n",
    "    1904 - Despedida / Dispensa Imotivada\n",
    "    2029 - FGTS\n",
    "    10570 - FGTS\n",
    "    2055 - Gratificação\n",
    "    5356 - Grupo Econômico\n",
    "    2086 - Horas Extras\n",
    "    1661 - Horas in Itinere\n",
    "    2021 - Indenização / Dobra / Terço Constitucional\n",
    "    8808 - Indenização por Dano Material\n",
    "    1855 - Indenização por Dano Moral\n",
    "    55220 - Indenização por Dano Moral\n",
    "    2140 - Intervalo Intrajornada\n",
    "    1907 - Justa Causa / Falta Grave\n",
    "    2215 - Multa Prevista em Norma Coletiva\n",
    "    2554 - Reconhecimento de Relação de Emprego\n",
    "    2656 - Reintegração / Readmissão ou Indenização\n",
    "    2435 - Rescisão Indireta\n",
    "    4437 - Revisão de Sentença Normativa\n",
    "    2458 - Salário / Diferença Salarial\n",
    "    2478 - Seguro Desemprego\n",
    "    2117 - Supressão / Redução de Horas Extras Habituais - Indenização\n",
    "    2704 - Tomador de Serviços / Terceirização\n",
    "    2546 - Verbas Rescisórias\n",
    "\n",
    "PS: O assunto de código 55220 (Indenização por Dano Moral) será agrupado com o assunto 1855 (Indenização por Dano Moral)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Pré-requisitos\n",
    "\n",
    "Para referência, os modelos treinados com este código foram treinados com 180.672 documentos. Como são trabalhados uma grande quantidade de textos por envolver grupos representativos de textos de 35 assuntos diferentes, recomenda-se a utilização mínima de 16 GB de memória RAM e 4 cores. Para cada quatro cores adicionais disponíveis, sugere-se acrescentar mais 16GB de memória.\n",
    "\n",
    "Os modelos são executados utilizando processamento paralelo, de forma que os modelos de SVM e RF usam 80% dos cores disponíveis, e o NB e MLP usam 35% dos cores (uma vez que tem maior uso de memória RAM) disponíveis.\n",
    "Entrada\n",
    "\n",
    "Como entrada, são esperados arquvios csv que contenham as colunas abaixo, na ordem apresentada. Nem todas as informações são utilizadas para a tarefa de classificação, mas foram recuperadas pois são úteis na identificação do documento:\n",
    "\n",
    "    index: número sequencial de cada linha\n",
    "    nr_processo: número do processo no formato do CNJ (NNNNNNN-DD.AAAA.JTR.OOOO)\n",
    "    id_processo_documento: Chave primária da tb_processo_documento\n",
    "    cd_assunto_nivel_5: Código do nível 5 do assunto principal, se houver. Se não houver, deve ficar vazio\n",
    "    cd_assunto_nivel_4: Código do nível 4 do assunto principal, se houver. Se não houver, deve ficar vazio\n",
    "    cd_assunto_nivel_3: Código do nível 3 do assunto principal, se houver. Se não houver, deve ficar vazio\n",
    "    cd_assunto_nivel_2: Código do nível 2 do assunto principal, se houver. Se não houver, deve ficar vazio\n",
    "    cd_assunto_nivel_1: Código do nível 1 do assunto principal, se houver. Se não houver, deve ficar vazio\n",
    "    tx_conteudo_documento: Conteúdo HTML completo do documento\n",
    "    ds_identificador_unico: Identificador único completo do documento\n",
    "    ds_identificador_unico_simplificado: 7 últimos dígitos do identificador único do documento (forma de identificação no PJe)\n",
    "    ds_orgao_julgador: Nome do órgão julgador do processo\n",
    "    ds_orgao_julgador_colegiado: Nome do órgão julgador colegiado do processo\n",
    "    dt_juntada: Data da juntada do documento\n",
    "\n",
    "É esperado um arquivo CSV por cada regional, com o nome no seguinte padrão: TRT_YY_documentosSelecionados.csv\n",
    "\n",
    "##### Onde:\n",
    "\n",
    "YY representa a sigla de cada regional, sendo obrigatório 2 dígitos.\n",
    "\n",
    "##### Exemplos:\n",
    "\n",
    "TRT_01_documentosSelecionados.csv\n",
    "\n",
    "TRT_22_documentosSelecionados.csv\n",
    "\n",
    "O diretório onde se deve buscar os arquivos deve ser passado com o parametro -dd no momento da chamada do código. Embora seja desejável, não é obrigatório ter arquivos de entrada de todos os regionais.\n",
    "Saída\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Saída\n",
    "\n",
    "Como saída deste pipeline, são gravados diversos arquivos. Seguem:\n",
    "\n",
    "    Balanceamento_Assuntos_XXX_Elementos.png: Imagem que mostra o balancemento dos assuntos no dataset separado para treinamento\n",
    "    Distribuição_Tamanho_Textos_XXXX.png: Imagens que mostram um boxplot com a distribuição da quantidade de palavras por documento com todos os docuementos e depois removendo-se os documentos com menos de 400 palavras e mais de 10.000 palavras\n",
    "    Modelo_XXX.p: Modelos que foram gerados, levando da forma de representação do texto e o algortimo utilizado\n",
    "    Feature.p: Modelo de transformação do texto\n",
    "    Metricas.csv: Arquivo que guarda todas as métricas escolhidas de todos os modelos testados (para o primeiro GridSearch, usa-se apenas o modelo vencedor)\n",
    "    predicao_XXX: Arquivo que contém a predição feita por cada combinação XXX de modelo e features, trazendo também o percentual probabilidade de cada um dos assuntos selecionados no escopo do projeto.\n",
    "    ClassificationReport_XXX.csv: Arquivo que da a métrica individual de cada um dos assuntos selecionados\n",
    "    MelhorModelo.p: Modelo vencedor\n",
    "    MelhorModeloFeature.p: Modelo de transformação de features vencedor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pré-requisitos\n",
    "\n",
    "Para referência, os modelos treinados com este código foram treinados com 180.672 documentos. Como são trabalhados uma grande quantidade de textos por envolver grupos representativos de textos de 35 assuntos diferentes, recomenda-se a utilização mínima de 16 GB de memória RAM e 4 cores. Para cada quatro cores adicionais disponíveis, sugere-se acrescentar mais 16GB de memória.\n",
    "\n",
    "Os modelos são executados utilizando processamento paralelo, de forma que os modelos de SVM e RF usam 80% dos cores disponíveis, e o NB e MLP usam 35% dos cores (uma vez que tem maior uso de memória RAM) disponíveis.\n",
    "Entrada\n",
    "\n",
    "Como entrada, são esperados arquvios csv que contenham as colunas abaixo, na ordem apresentada. Nem todas as informações são utilizadas para a tarefa de classificação, mas foram recuperadas pois são úteis na identificação do documento:\n",
    "\n",
    "    index: número sequencial de cada linha\n",
    "    nr_processo: número do processo no formato do CNJ (NNNNNNN-DD.AAAA.JTR.OOOO)\n",
    "    id_processo_documento: Chave primária da tb_processo_documento\n",
    "    cd_assunto_nivel_5: Código do nível 5 do assunto principal, se houver. Se não houver, deve ficar vazio\n",
    "    cd_assunto_nivel_4: Código do nível 4 do assunto principal, se houver. Se não houver, deve ficar vazio\n",
    "    cd_assunto_nivel_3: Código do nível 3 do assunto principal, se houver. Se não houver, deve ficar vazio\n",
    "    cd_assunto_nivel_2: Código do nível 2 do assunto principal, se houver. Se não houver, deve ficar vazio\n",
    "    cd_assunto_nivel_1: Código do nível 1 do assunto principal, se houver. Se não houver, deve ficar vazio\n",
    "    tx_conteudo_documento: Conteúdo HTML completo do documento\n",
    "    ds_identificador_unico: Identificador único completo do documento\n",
    "    ds_identificador_unico_simplificado: 7 últimos dígitos do identificador único do documento (forma de identificação no PJe)\n",
    "    ds_orgao_julgador: Nome do órgão julgador do processo\n",
    "    ds_orgao_julgador_colegiado: Nome do órgão julgador colegiado do processo\n",
    "    dt_juntada: Data da juntada do documento\n",
    "\n",
    "É esperado um arquivo CSV por cada regional, com o nome no seguinte padrão: TRT_YY_documentosSelecionados.csv\n",
    "\n",
    "##### Onde:\n",
    "\n",
    "YY representa a sigla de cada regional, sendo obrigatório 2 dígitos.\n",
    "\n",
    "##### Exemplos:\n",
    "\n",
    "TRT_01_documentosSelecionados.csv\n",
    "\n",
    "TRT_22_documentosSelecionados.csv\n",
    "\n",
    "O diretório onde se deve buscar os arquivos deve ser passado com o parametro -dd no momento da chamada do código. Embora seja desejável, não é obrigatório ter arquivos de entrada de todos os regionais.\n",
    "Saída\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saída\n",
    "\n",
    "Como saída deste pipeline, são gravados diversos arquivos. Seguem:\n",
    "\n",
    "    Balanceamento_Assuntos_XXX_Elementos.png: Imagem que mostra o balancemento dos assuntos no dataset separado para treinamento\n",
    "    Distribuição_Tamanho_Textos_XXXX.png: Imagens que mostram um boxplot com a distribuição da quantidade de palavras por documento com todos os docuementos e depois removendo-se os documentos com menos de 400 palavras e mais de 10.000 palavras\n",
    "    Modelo_XXX.p: Modelos que foram gerados, levando da forma de representação do texto e o algortimo utilizado\n",
    "    Feature.p: Modelo de transformação do texto\n",
    "    Metricas.csv: Arquivo que guarda todas as métricas escolhidas de todos os modelos testados (para o primeiro GridSearch, usa-se apenas o modelo vencedor)\n",
    "    predicao_XXX: Arquivo que contém a predição feita por cada combinação XXX de modelo e features, trazendo também o percentual probabilidade de cada um dos assuntos selecionados no escopo do projeto.\n",
    "    ClassificationReport_XXX.csv: Arquivo que da a métrica individual de cada um dos assuntos selecionados\n",
    "    MelhorModelo.p: Modelo vencedor\n",
    "    MelhorModeloFeature.p: Modelo de transformação de features vencedor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from docutils.nodes import header\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import os\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#!pip --trusted-host=pypi.python.org --trusted-host=pypi.org --trusted-host=files.pythonhosted.org install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando o ambiente de execução do conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import funcoes as func\n",
    "from modelo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "n_cores = mp.cpu_count()\n",
    "n_cores_grande = round(n_cores * 0.8)\n",
    "n_cores_pequeno = round(n_cores * 0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ATENÇÃO:\n",
    "\n",
    "A célula abaixo deve ser editada para conter o caminho correto para a pasta onde os dados serão buscados, e a pasta onde serão gravadas as saídas do processamento deste código. O caminho de cada pasta deve ser terminado com a '/' no final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "path_fonte_de_dados = '/home/anarocha/Documents/DocumentosClassificadorAssuntos/'\n",
    "path_resultados = '/home/anarocha/Documents/DocumentosClassificadorAssuntos/DocsProcessados/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(path_resultados):\n",
    "    os.makedirs(path_resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "float_formatter = lambda x: \"%.4f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "columnsResultados=['id_execucao', 'data', 'nome','feature_type','tempo_processamento','tamanho_conjunto_treinamento','accuracy','balanced_accuracy','micro_precision','micro_recall','micro_fscore','macro_precision','macro_recall','macro_fscore','best_params_','best_estimator_','grid_scores_','grid_cv_results','confusion_matrix','classification_report','num_estimators','max_samples']\n",
    "df_resultados = pd.DataFrame(columns = columnsResultados)\n",
    "nome_arquivo_destino = path_resultados + \"Metricas.csv\"\n",
    "if  not (os.path.isfile(nome_arquivo_destino)):\n",
    "    with open(nome_arquivo_destino, 'a') as f:\n",
    "        df_resultados.to_csv(f, header=True)\n",
    "nome_classification_reports = path_resultados + 'ClassificationReport'\n",
    "\n",
    "id_execucao = str(uuid.uuid1())[:7]\n",
    "data = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "modelos = []\n",
    "\n",
    "listaAssuntos=[2546,2086,1855,2594,2458,2704,2656,2140,2435,2029,2583,2554,8808,2117,2021,5280,1904,1844,2055,1907,1806,55220,2506,\n",
    "                        4437,10570,1783,1888,2478,5356,1773,1663,5272,2215,1767,1661,1690]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo modelos que serão usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "classificadorNB = MultinomialNB()\n",
    "classificadorRF = RandomForestClassifier(random_state=42)\n",
    "classificadorSVM = CalibratedClassifierCV(LinearSVC(class_weight='balanced', max_iter=10000,random_state=42),method='sigmoid', cv=5)\n",
    "classificadorMLP = MLPClassifier(early_stopping= True,random_state=42)\n",
    "\n",
    "nomeAlgoritmoNB='Multinomial Naive Bayes'\n",
    "nomeAlgoritmoRF='Random Forest'\n",
    "nomeAlgoritmoSVM='SVM'\n",
    "nomeAlgoritmoMLP=\"Multi-Layer Perceptron\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento dos documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "path_destino_de_dados = path_fonte_de_dados + 'DocumentosProcessados/'\n",
    "if not os.path.exists(path_destino_de_dados):\n",
    "        os.makedirs(path_destino_de_dados)\n",
    "        \n",
    "func.processaDocumentos(path_fonte_de_dados,path_destino_de_dados)\n",
    "print(\"Todos os documentos disponíveis foram processados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperando textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "qtdElementosPorAssunto=1000000\n",
    "df_amostra = func.recupera_amostras_de_todos_regionais(listaAssuntos, qtdElementosPorAssunto, path_destino_de_dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntando os assuntos 55220 e 1855, ambos Indenização por Dano Moral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_amostra.loc[df_amostra['cd_assunto_nivel_3'] == 55220, 'cd_assunto_nivel_3'] = 1855\n",
    "df_amostra.loc[df_amostra['cd_assunto_nivel_2'] == 55218, 'cd_assunto_nivel_3'] = 2567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print('Total de textos recuperados: ' + str(len(df_amostra)))\n",
    "df_amostra = df_amostra.dropna(subset=['texto_stemizado'])\n",
    "print('Total de textos recuperados com conteúdo: ' + str(len(df_amostra)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando tamanho dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_amostra['quantidade_de_palavras'] = [len(x.split()) for x in df_amostra['texto_processado'].tolist()]\n",
    "sns.boxplot(df_amostra['quantidade_de_palavras'])\n",
    "plt.savefig(\"{0}{1}.png\".format(path_resultados, \"Distribuicao_Tamanho_Textos_Original\"))\n",
    "\n",
    "df_amostra_f = df_amostra[((df_amostra.quantidade_de_palavras < 400) & (df_amostra.quantidade_de_palavras > 0))]\n",
    "print('Quantidade de textos entre 0 e 400 palavras: ' + str(len(df_amostra_f)))\n",
    "df_amostra_f = df_amostra[(df_amostra.quantidade_de_palavras > 10000)]\n",
    "print('Quantidade de textos com mais de 10.000 palavras: ' + str(len(df_amostra_f)))\n",
    "df_amostra.shape\n",
    "df_amostra_f = df_amostra[((df_amostra.quantidade_de_palavras < 10000) & (df_amostra.quantidade_de_palavras > 400))]\n",
    "df_amostra_f= df_amostra_f.sort_values(by='quantidade_de_palavras', ascending=True)\n",
    "df_amostra_f.shape\n",
    "df_amostra = df_amostra_f\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()\n",
    "sns.boxplot(df_amostra['quantidade_de_palavras'])\n",
    "plt.savefig(\"{0}{1}.png\".format(path_resultados, \"Distribuicao_Tamanho_Textos_Depois_Da_Remocao_De_Textos_Com_Mais_De_400_e_Menos_de_10000\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print('Total de textos utilizados: ' + str(len(df_amostra)))\n",
    "X_train, X_test, y_train, y_test = func.splitTrainTest(df_amostra)\n",
    "print(\"Amostra de teste de \" + str(X_test.shape[0]) + \" elementos\")\n",
    "print(\"Amostra de treinamento de \" + str(X_train.shape[0]) + \" elementos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "title = \"Balanceamento de assuntos na amostra de \"  + str(X_train.shape[0])\n",
    "func.mostra_balanceamento_assunto(y_train.value_counts(), title, \"Quantidade Elementos\", \"Código Assunto\", path_resultados, y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "tfidf_transformer,x_tfidf_train, x_tfidf_test = func.extraiFeaturesTFIDF_train_test(df_amostra, X_train['texto_stemizado'], X_test['texto_stemizado'], path_resultados)\n",
    "total_time = time.time() - start_time\n",
    "print(\"Tempo para montar matrizes TF-IDF (features:  \"+ str(x_tfidf_train.shape[1]) + \") :\" +   str(timedelta(seconds=total_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "bm25_transformer,x_bm25_train, x_bm25_test = func.extraiFeaturesBM25(df_amostra, tfidf_transformer, x_tfidf_train, x_tfidf_test, path_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "lsi100_transformer,x_lsi100_train, x_lsi100_test = func.extraiFeaturesLSI(df_amostra, X_train['texto_stemizado'], X_test['texto_stemizado'], 100, path_resultados)\n",
    "lsi250_transformer,x_lsi250_train, x_lsi250_test = func.extraiFeaturesLSI(df_amostra, X_train['texto_stemizado'], X_test['texto_stemizado'], 250, path_resultados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "#### Com TF-IDF\n",
    "\n",
    "Coloque aqui a quantidade de configurações diferentes a serem testadas no GridSearch para cada modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "numero_de_configuracoes_por_modelo=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naïve-Bayes (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "param_grid_NB = {\n",
    "    'estimator__n_estimators': [3,5],\n",
    "    'estimator__max_samples': [0.8,0.5],\n",
    "    'estimator__base_estimator__alpha': [0.0001, 0.001, 0.01, 0.1, 0.5, 1]\n",
    "}\n",
    "modeloNB = func.chama_treinamento_modelo(x_tfidf_train, y_train, x_tfidf_test,y_test, classificadorNB, nomeAlgoritmoNB , 'TFIDF',param_grid_NB,numero_de_configuracoes_por_modelo,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloNB.getNome(),modeloNB.getFeatureType(),modeloNB.getMicroPrecision(),modeloNB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "param_grid_SVM = {\n",
    "    'estimator__n_estimators': [3, 5],\n",
    "    'estimator__max_samples': [0.8, 0.5],\n",
    "    'estimator__base_estimator__base_estimator__C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "modeloSVM = func.chama_treinamento_modelo(x_tfidf_train,y_train, x_tfidf_test,y_test, classificadorSVM, nomeAlgoritmoSVM,'TFIDF',param_grid_SVM, numero_de_configuracoes_por_modelo,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloSVM.getNome(),modeloSVM.getFeatureType(),modeloSVM.getMicroPrecision(),modeloSVM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "param_grid_RF = {\n",
    "    'estimator__n_estimators': [3,5],\n",
    "    'estimator__max_samples': [0.8,0.5],\n",
    "    'estimator__base_estimator__max_depth': [30,50,100],\n",
    "    'estimator__base_estimator__n_estimators': [100,200,300],\n",
    "    'estimator__base_estimator__min_samples_leaf': [0.05, 0.1, 0.5],\n",
    "    'estimator__base_estimator__min_samples_split': [0.05, 0.1, 0.5],\n",
    "    'estimator__base_estimator__max_features': [0.3, 0.5, 0.8]\n",
    "}\n",
    "modeloRF = func.chama_treinamento_modelo(x_tfidf_train,y_train, x_tfidf_test,y_test, classificadorRF, nomeAlgoritmoRF,'TFIDF',param_grid_RF, numero_de_configuracoes_por_modelo,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloRF.getNome(),modeloRF.getFeatureType(),modeloRF.getMicroPrecision(),modeloRF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "param_grid_MLP = {\n",
    "    'estimator__n_estimators': [3,5],\n",
    "    'estimator__max_samples': [0.8,0.5],\n",
    "    'estimator__base_estimator__hidden_layer_sizes': [(10,10),(10,5,10)],\n",
    "    'estimator__base_estimator__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'estimator__base_estimator__solver': ['sgd', 'adam','lbfgs'],\n",
    "    'estimator__base_estimator__alpha': [0.001, 0.01, 0.05, 0.1],\n",
    "    'estimator__base_estimator__learning_rate': ['constant','adaptive','invscaling'],\n",
    "    'estimator__base_estimator__max_iter': [200,300,400]\n",
    "}\n",
    "modeloMLP = func.chama_treinamento_modelo(x_tfidf_train,y_train, x_tfidf_test,y_test, classificadorMLP,nomeAlgoritmoMLP, 'TFIDF',param_grid_MLP, numero_de_configuracoes_por_modelo,n_cores_pequeno,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloMLP.getNome(),modeloMLP.getFeatureType(),modeloMLP.getMicroPrecision(),modeloMLP])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando dicionarios com a melhor configuração de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#MNB\n",
    "param_grid_melhor_NB = {\n",
    "    'estimator__n_estimators': [modeloNB.getBestParams().get('estimator__n_estimators')],\n",
    "    'estimator__max_samples': [modeloNB.getBestParams().get('estimator__max_samples')],\n",
    "    'estimator__base_estimator__alpha': [modeloNB.getBestParams().get('estimator__base_estimator__alpha')]\n",
    "}\n",
    "\n",
    "# SVM\n",
    "param_grid_melhor_SVM = {\n",
    "    'estimator__n_estimators': [modeloSVM.getBestParams().get('estimator__n_estimators')],\n",
    "    'estimator__max_samples': [modeloSVM.getBestParams().get('estimator__max_samples')],\n",
    "    'estimator__base_estimator__base_estimator__C': [modeloSVM.getBestParams().get('estimator__base_estimator__base_estimator__C')]\n",
    "}\n",
    "\n",
    "# RF\n",
    "param_grid_melhor_RF = {\n",
    "    'estimator__n_estimators': [modeloRF.getBestParams().get('estimator__n_estimators')],\n",
    "    'estimator__max_samples': [modeloRF.getBestParams().get('estimator__max_samples')],\n",
    "    'estimator__base_estimator__max_depth': [modeloRF.getBestParams().get('estimator__base_estimator__max_depth')],\n",
    "    'estimator__base_estimator__n_estimators': [modeloRF.getBestParams().get('estimator__base_estimator__n_estimators')],\n",
    "    'estimator__base_estimator__min_samples_leaf': [modeloRF.getBestParams().get('estimator__base_estimator__min_samples_leaf')],\n",
    "    'estimator__base_estimator__min_samples_split': [modeloRF.getBestParams().get('estimator__base_estimator__min_samples_split')],\n",
    "    'estimator__base_estimator__max_features': [modeloRF.getBestParams().get('estimator__base_estimator__max_features')]\n",
    "}\n",
    "\n",
    "# MLP\n",
    "param_grid_melhor_MLP = {\n",
    "    'estimator__n_estimators': [modeloMLP.getBestParams().get('estimator__n_estimators')],\n",
    "    'estimator__max_samples': [modeloMLP.getBestParams().get('estimator__max_samples')],\n",
    "    'estimator__base_estimator__hidden_layer_sizes': [modeloMLP.getBestParams().get('estimator__base_estimator__hidden_layer_sizes')],\n",
    "    'estimator__base_estimator__activation': [modeloMLP.getBestParams().get('estimator__base_estimator__activation')],\n",
    "    'estimator__base_estimator__solver': [modeloMLP.getBestParams().get('estimator__base_estimator__solver')],\n",
    "    'estimator__base_estimator__alpha': [modeloMLP.getBestParams().get('estimator__base_estimator__alpha')],\n",
    "    'estimator__base_estimator__learning_rate': [modeloMLP.getBestParams().get('estimator__base_estimator__learning_rate')],\n",
    "    'estimator__base_estimator__max_iter': [modeloMLP.getBestParams().get('estimator__base_estimator__max_iter')]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "modeloNB_BM25 = func.chama_treinamento_modelo(x_bm25_train,y_train, x_bm25_test,y_test, classificadorNB, nomeAlgoritmoNB,'BM25',param_grid_melhor_NB, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloNB_BM25.getNome(),modeloNB_BM25.getFeatureType(),modeloNB_BM25.getMicroPrecision(),modeloNB_BM25])\n",
    "\n",
    "modeloSVM_BM25 = func.chama_treinamento_modelo(x_bm25_train,y_train, x_bm25_test,y_test, classificadorSVM, nomeAlgoritmoSVM,'BM25',param_grid_melhor_SVM, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloSVM_BM25.getNome(),modeloSVM_BM25.getFeatureType(),modeloSVM_BM25.getMicroPrecision(),modeloSVM_BM25])\n",
    "\n",
    "modeloRF_BM25 = func.chama_treinamento_modelo(x_bm25_train,y_train, x_bm25_test,y_test, classificadorRF, nomeAlgoritmoRF,'BM25',param_grid_melhor_RF, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloRF_BM25.getNome(),modeloRF_BM25.getFeatureType(),modeloRF_BM25.getMicroPrecision(),modeloRF_BM25])\n",
    "\n",
    "modeloMLP_BM25 = func.chama_treinamento_modelo(x_bm25_train,y_train, x_bm25_test,y_test, classificadorMLP, nomeAlgoritmoMLP,'BM25',param_grid_melhor_MLP, 1,n_cores_pequeno,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloMLP_BM25.getNome(),modeloMLP_BM25.getFeatureType(),modeloMLP_BM25.getMicroPrecision(),modeloMLP_BM25])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSI 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "modeloSVM_LSI100 = func.chama_treinamento_modelo(x_lsi100_train,y_train, x_lsi100_test ,y_test, classificadorSVM,nomeAlgoritmoSVM, 'LSI100',param_grid_melhor_SVM, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloSVM_LSI100.getNome(),modeloSVM_LSI100.getFeatureType(),modeloSVM_LSI100.getMicroPrecision(),modeloSVM_LSI100])\n",
    "\n",
    "modeloRF_LSI100 = func.chama_treinamento_modelo(x_lsi100_train, y_train,x_lsi100_test ,y_test, classificadorRF,nomeAlgoritmoRF, 'LSI100',param_grid_melhor_RF, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloRF_LSI100.getNome(),modeloRF_LSI100.getFeatureType(),modeloRF_LSI100.getMicroPrecision(),modeloRF_LSI100])\n",
    "\n",
    "modeloMLP_LSI100 = func.chama_treinamento_modelo(x_lsi100_train,y_train, x_lsi100_test ,y_test, classificadorMLP, nomeAlgoritmoMLP,'LSI100',param_grid_melhor_MLP, 1,n_cores_pequeno,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloMLP_LSI100.getNome(),modeloMLP_LSI100.getFeatureType(),modeloMLP_LSI100.getMicroPrecision(),modeloMLP_LSI100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSI 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "modeloSVM_LSI250 = func.chama_treinamento_modelo(x_lsi250_train,y_train, x_lsi250_test ,y_test, classificadorSVM,nomeAlgoritmoSVM, 'LSI250',param_grid_melhor_SVM, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloSVM_LSI250.getNome(),modeloSVM_LSI250.getFeatureType(),modeloSVM_LSI250.getMicroPrecision(),modeloSVM_LSI250])\n",
    "\n",
    "modeloRF_LSI250 = func.chama_treinamento_modelo(x_lsi250_train, y_train,x_lsi250_test ,y_test, classificadorRF,nomeAlgoritmoRF, 'LSI250',param_grid_melhor_RF, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloRF_LSI250.getNome(),modeloRF_LSI250.getFeatureType(),modeloRF_LSI250.getMicroPrecision(),modeloRF_LSI250])\n",
    "\n",
    "modeloMLP_LSI250 = func.chama_treinamento_modelo(x_lsi250_train,y_train, x_lsi250_test ,y_test, classificadorMLP, nomeAlgoritmoMLP,'LSI250',param_grid_melhor_MLP, 1,n_cores_pequeno,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloMLP_LSI250.getNome(),modeloMLP_LSI250.getFeatureType(),modeloMLP_LSI250.getMicroPrecision(),modeloMLP_LSI250])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrando o modelo vencedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "modelos_df = pd.DataFrame(modelos, columns=['Nome Modelo','Feature Type','micro_precision','Modelo'])\n",
    "modelos_df= modelos_df.sort_values(by='micro_precision', ascending=False)\n",
    "print(\"O modelo vencedor foi o \" + modelos_df.iloc[0]['Nome Modelo'] + \", com \" + (str(\"%.2f\" % modelos_df.iloc[0]['micro_precision'])) + \" de micro precisão\")\n",
    "\n",
    "modelo_vencedor = modelos_df.iloc[0]['Modelo']\n",
    "\n",
    "arquivoPickle = open(path_resultados + \"MelhorModelo.p\", 'wb')\n",
    "pickle.dump(modelo_vencedor.getBestEstimator(), arquivoPickle)\n",
    "arquivoPickle.close()\n",
    "\n",
    "if modelo_vencedor.getFeatureType() == 'LSI100':\n",
    "    feature_vencedora = open(path_resultados + \"MelhorModeloFeature.p\", 'wb')\n",
    "    pickle.dump(lsi100_transformer, feature_vencedora)\n",
    "    feature_vencedora.close()\n",
    "elif modelo_vencedor.getFeatureType() == 'LSI250':\n",
    "    feature_vencedora = open(path_resultados + \"MelhorModeloFeature.p\", 'wb')\n",
    "    pickle.dump(lsi250_transformer, feature_vencedora)\n",
    "    feature_vencedora.close()\n",
    "elif modelo_vencedor.getFeatureType() == 'TFIDF':\n",
    "    feature_vencedora = open(path_resultados + \"MelhorModeloFeature.p\", 'wb')\n",
    "    pickle.dump(tfidf_transformer, feature_vencedora)\n",
    "    feature_vencedora.close()\n",
    "elif modelo_vencedor.getFeatureType() == 'BM25':\n",
    "    feature_vencedora = open(path_resultados + \"MelhorModeloFeature.p\", 'wb')\n",
    "    pickle.dump(bm25_transformer, feature_vencedora)\n",
    "    feature_vencedora.close()\n",
    "    \n",
    "print(\"O modelo para transformação dos textos pré-processados se encontra no arquivo \" + path_resultados + \"MelhorModeloFeature.p\" + \" e o modelo de classificação no arquivo \" + path_resultados + \"MelhorModelo.p\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}