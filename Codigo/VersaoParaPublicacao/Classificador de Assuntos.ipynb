{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificador de Assuntos\n",
    "\n",
    "Por Ana Carolina Pereira Rocha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from docutils.nodes import header\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import os\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import argparse\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#!pip --trusted-host=pypi.python.org --trusted-host=pypi.org --trusted-host=files.pythonhosted.org install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando o ambiente de execução do conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "envppca\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import funcoes as func\n",
    "from modelo import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "n_cores = mp.cpu_count()\n",
    "n_cores_grande = round(n_cores * 0.8)\n",
    "n_cores_pequeno = round(n_cores * 0.35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ATENÇÃO:\n",
    "\n",
    "A célula abaixo deve ser editada para conter o caminho correto para a pasta onde os dados serão buscados, e a pasta onde serão gravadas as saídas do processamento deste código. O caminho de cada pasta deve ser terminado com a '/' no final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "path_fonte_de_dados = '/home/anarocha/Documents/DocumentosClassificadorAssuntos/'\n",
    "path_resultados = '/home/anarocha/Documents/DocumentosClassificadorAssuntos/DocsProcessados/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(path_resultados):\n",
    "    os.makedirs(path_resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "float_formatter = lambda x: \"%.4f\" % x\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})\n",
    "\n",
    "columnsResultados=['id_execucao', 'data', 'nome','feature_type','tempo_processamento','tamanho_conjunto_treinamento','accuracy','balanced_accuracy','micro_precision','micro_recall','micro_fscore','macro_precision','macro_recall','macro_fscore','best_params_','best_estimator_','grid_scores_','grid_cv_results','confusion_matrix','classification_report','num_estimators','max_samples']\n",
    "df_resultados = pd.DataFrame(columns = columnsResultados)\n",
    "nome_arquivo_destino = path_resultados + \"Metricas.csv\"\n",
    "if  not (os.path.isfile(nome_arquivo_destino)):\n",
    "    with open(nome_arquivo_destino, 'a') as f:\n",
    "        df_resultados.to_csv(f, header=True)\n",
    "nome_classification_reports = path_resultados + 'ClassificationReport'\n",
    "\n",
    "id_execucao = str(uuid.uuid1())[:7]\n",
    "data = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "\n",
    "modelos = []\n",
    "\n",
    "listaAssuntos=[2546,2086,1855,2594,2458,2704,2656,2140,2435,2029,2583,2554,8808,2117,2021,5280,1904,1844,2055,1907,1806,55220,2506,\n",
    "                        4437,10570,1783,1888,2478,5356,1773,1663,5272,2215,1767,1661,1690]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definindo modelos que serão usados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "classificadorNB = MultinomialNB()\n",
    "classificadorRF = RandomForestClassifier(random_state=42)\n",
    "classificadorSVM = CalibratedClassifierCV(LinearSVC(class_weight='balanced', max_iter=10000,random_state=42),method='sigmoid', cv=5)\n",
    "classificadorMLP = MLPClassifier(early_stopping= True,random_state=42)\n",
    "\n",
    "nomeAlgoritmoNB='Multinomial Naive Bayes'\n",
    "nomeAlgoritmoRF='Random Forest'\n",
    "nomeAlgoritmoSVM='SVM'\n",
    "nomeAlgoritmoMLP=\"Multi-Layer Perceptron\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré-processamento dos documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Todos os documentos disponíveis foram processados\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "path_destino_de_dados = path_fonte_de_dados + 'DocumentosProcessados/'\n",
    "if not os.path.exists(path_destino_de_dados):\n",
    "        os.makedirs(path_destino_de_dados)\n",
    "        \n",
    "#func.processaDocumentos(path_fonte_de_dados,path_destino_de_dados)\n",
    "print(\"Todos os documentos disponíveis foram processados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperando textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Buscando 200 elementos de cada assunto em cada regional\n",
      "Não foi encontrado o arquivo de documentos do TRT 01. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_01_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 05. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_05_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 02. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_02_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 04. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_04_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 03. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_03_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 06. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_06_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 07. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_07_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 11. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_11_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 10. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_10_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 12. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_12_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 14. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_14_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 13. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_13_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 16. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_16_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 15. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_15_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 17. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_17_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 18. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_18_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 20. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_20_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 21. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_21_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 22. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_22_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 23. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_23_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 19. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_19_documentosSelecionadosProcessados.csv\n",
      "Não foi encontrado o arquivo de documentos do TRT 24. Buscou-se pelo arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocumentosProcessados/TRT_24_documentosSelecionadosProcessados.csv\n",
      "Quantidade de documentos recuperados no TRT 09: 600\n",
      "Quantidade de documentos recuperados no TRT 08: 600\n",
      "(1200, 16)\n",
      "Tempo para recuperar amostra de todos os regionais  0:00:02.415509\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "qtdElementosPorAssunto=1000000\n",
    "df_amostra = func.recupera_amostras_de_todos_regionais(listaAssuntos, qtdElementosPorAssunto, path_destino_de_dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntando os assuntos 55220 e 1855, ambos Indenização por Dano Moral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_amostra.loc[df_amostra['cd_assunto_nivel_3'] == 55220, 'cd_assunto_nivel_3'] = 1855\n",
    "df_amostra.loc[df_amostra['cd_assunto_nivel_2'] == 55218, 'cd_assunto_nivel_3'] = 2567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Total de textos recuperados: 1200\n",
      "Total de textos recuperados com conteúdo: 1197\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Total de textos recuperados: ' + str(len(df_amostra)))\n",
    "df_amostra = df_amostra.dropna(subset=['texto_stemizado'])\n",
    "print('Total de textos recuperados com conteúdo: ' + str(len(df_amostra)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando tamanho dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Quantidade de textos entre 0 e 400 palavras: 260\n",
      "Quantidade de textos com mais de 10.000 palavras: 46\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_amostra['quantidade_de_palavras'] = [len(x.split()) for x in df_amostra['texto_processado'].tolist()]\n",
    "sns.boxplot(df_amostra['quantidade_de_palavras'])\n",
    "plt.savefig(\"{0}{1}.png\".format(path_resultados, \"Distribuicao_Tamanho_Textos_Original\"))\n",
    "\n",
    "df_amostra_f = df_amostra[((df_amostra.quantidade_de_palavras < 400) & (df_amostra.quantidade_de_palavras > 0))]\n",
    "print('Quantidade de textos entre 0 e 400 palavras: ' + str(len(df_amostra_f)))\n",
    "df_amostra_f = df_amostra[(df_amostra.quantidade_de_palavras > 10000)]\n",
    "print('Quantidade de textos com mais de 10.000 palavras: ' + str(len(df_amostra_f)))\n",
    "df_amostra.shape\n",
    "df_amostra_f = df_amostra[((df_amostra.quantidade_de_palavras < 10000) & (df_amostra.quantidade_de_palavras > 400))]\n",
    "df_amostra_f= df_amostra_f.sort_values(by='quantidade_de_palavras', ascending=True)\n",
    "df_amostra_f.shape\n",
    "df_amostra = df_amostra_f\n",
    "plt.clf()\n",
    "plt.cla()\n",
    "plt.close()\n",
    "sns.boxplot(df_amostra['quantidade_de_palavras'])\n",
    "plt.savefig(\"{0}{1}.png\".format(path_resultados, \"Distribuicao_Tamanho_Textos_Depois_Da_Remocao_De_Textos_Com_Mais_De_400_e_Menos_de_10000\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Total de textos utilizados: 891\n",
      "Amostra de teste de 179 elementos\n",
      "Amostra de treinamento de 712 elementos\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('Total de textos utilizados: ' + str(len(df_amostra)))\n",
    "X_train, X_test, y_train, y_test = func.splitTrainTest(df_amostra)\n",
    "print(\"Amostra de teste de \" + str(X_test.shape[0]) + \" elementos\")\n",
    "print(\"Amostra de treinamento de \" + str(X_train.shape[0]) + \" elementos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "title = \"Balanceamento de assuntos na amostra de \"  + str(X_train.shape[0])\n",
    "func.mostra_balanceamento_assunto(y_train.value_counts(), title, \"Quantidade Elementos\", \"Código Assunto\", path_resultados, y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando matrizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Tempo para montar matrizes TF-IDF (features:  6304) :0:00:02.406011\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tfidf_transformer,x_tfidf_train, x_tfidf_test = func.extraiFeaturesTFIDF_train_test(df_amostra, X_train['texto_stemizado'], X_test['texto_stemizado'], path_resultados)\n",
    "total_time = time.time() - start_time\n",
    "print(\"Tempo para montar matrizes TF-IDF (features:  \"+ str(x_tfidf_train.shape[1]) + \") :\" +   str(timedelta(seconds=total_time)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/anarocha/Documents/myGit/classificadorDeAssuntos/Codigo/VersaoParaPublicacao/BM25_Transformer.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n",
      "/home/anarocha/Documents/myGit/classificadorDeAssuntos/Codigo/VersaoParaPublicacao/BM25_Transformer.py:52: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "bm25_transformer,x_bm25_train, x_bm25_test = func.extraiFeaturesBM25(df_amostra, tfidf_transformer, x_tfidf_train, x_tfidf_test, path_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "lsi100_transformer,x_lsi100_train, x_lsi100_test = func.extraiFeaturesLSI(df_amostra, X_train['texto_stemizado'], X_test['texto_stemizado'], 100, path_resultados)\n",
    "lsi250_transformer,x_lsi250_train, x_lsi250_test = func.extraiFeaturesLSI(df_amostra, X_train['texto_stemizado'], X_test['texto_stemizado'], 250, path_resultados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "#### Com TF-IDF\n",
    "\n",
    "Coloque aqui a quantidade de configurações diferentes a serem testadas no GridSearch para cada modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "numero_de_configuracoes_por_modelo=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naïve-Bayes (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">> Fazendo Grid Search para classificador Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging Multinomial Naive Bayes para 712 elementos:  0:00:02.764313\n",
      ">> Testando classificador TFIDF_Multinomial Naive Bayes\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.042968\n",
      "Tempo para recuperar métricas:  0:00:00.007390\n",
      " \n",
      "Nome modelo: TFIDF_Multinomial Naive Bayes\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:00.114591\n",
      "Feature Type: TFIDF\n",
      "Accuracy: 0.5363128491620112\n",
      "Balanced Accuracy: 0.5387004585139125\n",
      "macro_precision 0.5281920125909896 \n",
      "macro_recall    0.5387004585139125 \n",
      "macro_fscore    0.5292326558868615\n",
      "micro_precision 0.5274493684172348 \n",
      "micro_recall    0.5363128491620112 \n",
      "micro_fscore    0.5276427498199544\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed:    2.6s finished\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "param_grid_NB = {\n",
    "    'estimator__n_estimators': [3,5],\n",
    "    'estimator__max_samples': [0.8,0.5],\n",
    "    'estimator__base_estimator__alpha': [0.0001, 0.001, 0.01, 0.1, 0.5, 1]\n",
    "}\n",
    "modeloNB = func.chama_treinamento_modelo(x_tfidf_train, y_train, x_tfidf_test,y_test, classificadorNB, nomeAlgoritmoNB , 'TFIDF',param_grid_NB,numero_de_configuracoes_por_modelo,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloNB.getNome(),modeloNB.getFeatureType(),modeloNB.getMicroPrecision(),modeloNB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">> Fazendo Grid Search para classificador SVM\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging SVM para 712 elementos:  0:00:06.258452\n",
      ">> Testando classificador TFIDF_SVM\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.155959\n",
      "Tempo para recuperar métricas:  0:00:00.011008\n",
      " \n",
      "Nome modelo: TFIDF_SVM\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:00.746663\n",
      "Feature Type: TFIDF\n",
      "Accuracy: 0.5307262569832403\n",
      "Balanced Accuracy: 0.5323063877897117\n",
      "macro_precision 0.5283216960129528 \n",
      "macro_recall    0.5323063877897117 \n",
      "macro_fscore    0.5292641309747511\n",
      "micro_precision 0.527678138345324 \n",
      "micro_recall    0.5307262569832403 \n",
      "micro_fscore    0.5281530146348951\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed:    5.5s finished\n",
      "/home/anarocha/anaconda3/envs/envppca/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "param_grid_SVM = {\n",
    "    'estimator__n_estimators': [3, 5],\n",
    "    'estimator__max_samples': [0.8, 0.5],\n",
    "    'estimator__base_estimator__base_estimator__C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "modeloSVM = func.chama_treinamento_modelo(x_tfidf_train,y_train, x_tfidf_test,y_test, classificadorSVM, nomeAlgoritmoSVM,'TFIDF',param_grid_SVM, numero_de_configuracoes_por_modelo,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloSVM.getNome(),modeloSVM.getFeatureType(),modeloSVM.getMicroPrecision(),modeloSVM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest (RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">> Fazendo Grid Search para classificador Random Forest\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging Random Forest para 712 elementos:  0:00:36.034927\n",
      ">> Testando classificador TFIDF_Random Forest\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:01.665103\n",
      "Tempo para recuperar métricas:  0:00:00.010965\n",
      " \n",
      "Nome modelo: TFIDF_Random Forest\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:08.830328\n",
      "Feature Type: TFIDF\n",
      "Accuracy: 0.5698324022346368\n",
      "Balanced Accuracy: 0.5716066829972992\n",
      "macro_precision 0.5736793311893718 \n",
      "macro_recall    0.5716066829972992 \n",
      "macro_fscore    0.5671145355243238\n",
      "micro_precision 0.5736389096324579 \n",
      "micro_recall    0.5698324022346368 \n",
      "micro_fscore    0.5662683873227097\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed:   27.2s finished\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "param_grid_RF = {\n",
    "    'estimator__n_estimators': [3,5],\n",
    "    'estimator__max_samples': [0.8,0.5],\n",
    "    'estimator__base_estimator__max_depth': [30,50,100],\n",
    "    'estimator__base_estimator__n_estimators': [100,200,300],\n",
    "    'estimator__base_estimator__min_samples_leaf': [0.05, 0.1, 0.5],\n",
    "    'estimator__base_estimator__min_samples_split': [0.05, 0.1, 0.5],\n",
    "    'estimator__base_estimator__max_features': [0.3, 0.5, 0.8]\n",
    "}\n",
    "modeloRF = func.chama_treinamento_modelo(x_tfidf_train,y_train, x_tfidf_test,y_test, classificadorRF, nomeAlgoritmoRF,'TFIDF',param_grid_RF, numero_de_configuracoes_por_modelo,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloRF.getNome(),modeloRF.getFeatureType(),modeloRF.getMicroPrecision(),modeloRF])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">> Fazendo Grid Search para classificador Multi-Layer Perceptron\n",
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=  18.2s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=  16.4s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=  18.4s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=  13.9s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=  14.6s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=sgd, estimator__base_estimator__max_iter=200, estimator__base_estimator__learning_rate=adaptive, estimator__base_estimator__hidden_layer_sizes=(10, 5, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=sgd, estimator__base_estimator__max_iter=200, estimator__base_estimator__learning_rate=adaptive, estimator__base_estimator__hidden_layer_sizes=(10, 5, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=  12.7s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=sgd, estimator__base_estimator__max_iter=200, estimator__base_estimator__learning_rate=adaptive, estimator__base_estimator__hidden_layer_sizes=(10, 5, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=sgd, estimator__base_estimator__max_iter=200, estimator__base_estimator__learning_rate=adaptive, estimator__base_estimator__hidden_layer_sizes=(10, 5, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=  11.6s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=sgd, estimator__base_estimator__max_iter=200, estimator__base_estimator__learning_rate=adaptive, estimator__base_estimator__hidden_layer_sizes=(10, 5, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=sgd, estimator__base_estimator__max_iter=200, estimator__base_estimator__learning_rate=adaptive, estimator__base_estimator__hidden_layer_sizes=(10, 5, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   8.2s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=sgd, estimator__base_estimator__max_iter=200, estimator__base_estimator__learning_rate=adaptive, estimator__base_estimator__hidden_layer_sizes=(10, 5, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=sgd, estimator__base_estimator__max_iter=200, estimator__base_estimator__learning_rate=adaptive, estimator__base_estimator__hidden_layer_sizes=(10, 5, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   9.1s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=sgd, estimator__base_estimator__max_iter=200, estimator__base_estimator__learning_rate=adaptive, estimator__base_estimator__hidden_layer_sizes=(10, 5, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=sgd, estimator__base_estimator__max_iter=200, estimator__base_estimator__learning_rate=adaptive, estimator__base_estimator__hidden_layer_sizes=(10, 5, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=  12.4s\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging Multi-Layer Perceptron para 712 elementos:  0:02:31.795842\n",
      ">> Testando classificador TFIDF_Multi-Layer Perceptron\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.048632\n",
      "Tempo para recuperar métricas:  0:00:00.008688\n",
      " \n",
      "Nome modelo: TFIDF_Multi-Layer Perceptron\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:16.459701\n",
      "Feature Type: TFIDF\n",
      "Accuracy: 0.5754189944134078\n",
      "Balanced Accuracy: 0.5770334777966208\n",
      "macro_precision 0.5771717171717171 \n",
      "macro_recall    0.5770334777966208 \n",
      "macro_fscore    0.5702388425552267\n",
      "micro_precision 0.5766802099204333 \n",
      "micro_recall    0.5754189944134078 \n",
      "micro_fscore    0.5690779041787468\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   18.2s remaining:    0.0s\n",
      "/home/anarocha/anaconda3/envs/envppca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anarocha/anaconda3/envs/envppca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anarocha/anaconda3/envs/envppca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anarocha/anaconda3/envs/envppca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/anarocha/anaconda3/envs/envppca/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  2.3min finished\n",
      "/home/anarocha/anaconda3/envs/envppca/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "param_grid_MLP = {\n",
    "    'estimator__n_estimators': [3,5],\n",
    "    'estimator__max_samples': [0.8,0.5],\n",
    "    'estimator__base_estimator__hidden_layer_sizes': [(10,10),(10,5,10)],\n",
    "    'estimator__base_estimator__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'estimator__base_estimator__solver': ['sgd', 'adam','lbfgs'],\n",
    "    'estimator__base_estimator__alpha': [0.001, 0.01, 0.05, 0.1],\n",
    "    'estimator__base_estimator__learning_rate': ['constant','adaptive','invscaling'],\n",
    "    'estimator__base_estimator__max_iter': [200,300,400]\n",
    "}\n",
    "modeloMLP = func.chama_treinamento_modelo(x_tfidf_train,y_train, x_tfidf_test,y_test, classificadorMLP,nomeAlgoritmoMLP, 'TFIDF',param_grid_MLP, numero_de_configuracoes_por_modelo,n_cores_pequeno,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloMLP.getNome(),modeloMLP.getFeatureType(),modeloMLP.getMicroPrecision(),modeloMLP])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando dicionarios com a melhor configuração de cada modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#MNB\n",
    "param_grid_melhor_NB = {\n",
    "    'estimator__n_estimators': [modeloNB.getBestParams().get('estimator__n_estimators')],\n",
    "    'estimator__max_samples': [modeloNB.getBestParams().get('estimator__max_samples')],\n",
    "    'estimator__base_estimator__alpha': [modeloNB.getBestParams().get('estimator__base_estimator__alpha')]\n",
    "}\n",
    "\n",
    "# SVM\n",
    "param_grid_melhor_SVM = {\n",
    "    'estimator__n_estimators': [modeloSVM.getBestParams().get('estimator__n_estimators')],\n",
    "    'estimator__max_samples': [modeloSVM.getBestParams().get('estimator__max_samples')],\n",
    "    'estimator__base_estimator__base_estimator__C': [modeloSVM.getBestParams().get('estimator__base_estimator__base_estimator__C')]\n",
    "}\n",
    "\n",
    "# RF\n",
    "param_grid_melhor_RF = {\n",
    "    'estimator__n_estimators': [modeloRF.getBestParams().get('estimator__n_estimators')],\n",
    "    'estimator__max_samples': [modeloRF.getBestParams().get('estimator__max_samples')],\n",
    "    'estimator__base_estimator__max_depth': [modeloRF.getBestParams().get('estimator__base_estimator__max_depth')],\n",
    "    'estimator__base_estimator__n_estimators': [modeloRF.getBestParams().get('estimator__base_estimator__n_estimators')],\n",
    "    'estimator__base_estimator__min_samples_leaf': [modeloRF.getBestParams().get('estimator__base_estimator__min_samples_leaf')],\n",
    "    'estimator__base_estimator__min_samples_split': [modeloRF.getBestParams().get('estimator__base_estimator__min_samples_split')],\n",
    "    'estimator__base_estimator__max_features': [modeloRF.getBestParams().get('estimator__base_estimator__max_features')]\n",
    "}\n",
    "\n",
    "# MLP\n",
    "param_grid_melhor_MLP = {\n",
    "    'estimator__n_estimators': [modeloMLP.getBestParams().get('estimator__n_estimators')],\n",
    "    'estimator__max_samples': [modeloMLP.getBestParams().get('estimator__max_samples')],\n",
    "    'estimator__base_estimator__hidden_layer_sizes': [modeloMLP.getBestParams().get('estimator__base_estimator__hidden_layer_sizes')],\n",
    "    'estimator__base_estimator__activation': [modeloMLP.getBestParams().get('estimator__base_estimator__activation')],\n",
    "    'estimator__base_estimator__solver': [modeloMLP.getBestParams().get('estimator__base_estimator__solver')],\n",
    "    'estimator__base_estimator__alpha': [modeloMLP.getBestParams().get('estimator__base_estimator__alpha')],\n",
    "    'estimator__base_estimator__learning_rate': [modeloMLP.getBestParams().get('estimator__base_estimator__learning_rate')],\n",
    "    'estimator__base_estimator__max_iter': [modeloMLP.getBestParams().get('estimator__base_estimator__max_iter')]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">> Fazendo Grid Search para classificador Multinomial Naive Bayes\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging Multinomial Naive Bayes para 712 elementos:  0:00:00.413208\n",
      ">> Testando classificador BM25_Multinomial Naive Bayes\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.072386\n",
      "Tempo para recuperar métricas:  0:00:00.017164\n",
      " \n",
      "Nome modelo: BM25_Multinomial Naive Bayes\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:00.114066\n",
      "Feature Type: BM25\n",
      "Accuracy: 0.5363128491620112\n",
      "Balanced Accuracy: 0.5383078952327115\n",
      "macro_precision 0.5283235581622678 \n",
      "macro_recall    0.5383078952327115 \n",
      "macro_fscore    0.5242365477423655\n",
      "micro_precision 0.5276212749225905 \n",
      "micro_recall    0.5363128491620112 \n",
      "micro_fscore    0.5227494388308463\n",
      ">> Fazendo Grid Search para classificador SVM\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging SVM para 712 elementos:  0:00:04.808151\n",
      ">> Testando classificador BM25_SVM\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.078866\n",
      "Tempo para recuperar métricas:  0:00:00.006486\n",
      " \n",
      "Nome modelo: BM25_SVM\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:01.457695\n",
      "Feature Type: BM25\n",
      "Accuracy: 0.547486033519553\n",
      "Balanced Accuracy: 0.549255700018843\n",
      "macro_precision 0.5454239220563847 \n",
      "macro_recall    0.549255700018843 \n",
      "macro_fscore    0.5440673690792411\n",
      "micro_precision 0.5449211692931989 \n",
      "micro_recall    0.547486033519553 \n",
      "micro_fscore    0.542892331153605\n",
      ">> Fazendo Grid Search para classificador Random Forest\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging Random Forest para 712 elementos:  0:00:30.552605\n",
      ">> Testando classificador BM25_Random Forest\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:01.460871\n",
      "Tempo para recuperar métricas:  0:00:00.007707\n",
      " \n",
      "Nome modelo: BM25_Random Forest\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:10.333253\n",
      "Feature Type: BM25\n",
      "Accuracy: 0.5586592178770949\n",
      "Balanced Accuracy: 0.5606777212486653\n",
      "macro_precision 0.5640697488401855 \n",
      "macro_recall    0.5606777212486653 \n",
      "macro_fscore    0.5556056286981103\n",
      "micro_precision 0.5641861547962382 \n",
      "micro_recall    0.5586592178770949 \n",
      "micro_fscore    0.5547371680528794\n",
      ">> Fazendo Grid Search para classificador Multi-Layer Perceptron\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   8.6s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   7.4s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   7.1s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   7.8s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   7.7s\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging Multi-Layer Perceptron para 712 elementos:  0:00:47.615296\n",
      ">> Testando classificador BM25_Multi-Layer Perceptron\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.051241\n",
      "Tempo para recuperar métricas:  0:00:00.008020\n",
      " \n",
      "Nome modelo: BM25_Multi-Layer Perceptron\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:08.975149\n",
      "Feature Type: BM25\n",
      "Accuracy: 0.5754189944134078\n",
      "Balanced Accuracy: 0.5761949626279756\n",
      "macro_precision 0.5747679549604382 \n",
      "macro_recall    0.5761949626279756 \n",
      "macro_fscore    0.5741841162044897\n",
      "micro_precision 0.5748337283277287 \n",
      "micro_recall    0.5754189944134078 \n",
      "micro_fscore    0.5738144694950569\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:    1.9s remaining:    1.3s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    3.3s finished\n",
      "/home/anarocha/anaconda3/envs/envppca/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:   10.7s remaining:    7.2s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:   20.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    8.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   38.6s finished\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "modeloNB_BM25 = func.chama_treinamento_modelo(x_bm25_train,y_train, x_bm25_test,y_test, classificadorNB, nomeAlgoritmoNB,'BM25',param_grid_melhor_NB, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloNB_BM25.getNome(),modeloNB_BM25.getFeatureType(),modeloNB_BM25.getMicroPrecision(),modeloNB_BM25])\n",
    "\n",
    "modeloSVM_BM25 = func.chama_treinamento_modelo(x_bm25_train,y_train, x_bm25_test,y_test, classificadorSVM, nomeAlgoritmoSVM,'BM25',param_grid_melhor_SVM, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloSVM_BM25.getNome(),modeloSVM_BM25.getFeatureType(),modeloSVM_BM25.getMicroPrecision(),modeloSVM_BM25])\n",
    "\n",
    "modeloRF_BM25 = func.chama_treinamento_modelo(x_bm25_train,y_train, x_bm25_test,y_test, classificadorRF, nomeAlgoritmoRF,'BM25',param_grid_melhor_RF, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloRF_BM25.getNome(),modeloRF_BM25.getFeatureType(),modeloRF_BM25.getMicroPrecision(),modeloRF_BM25])\n",
    "\n",
    "modeloMLP_BM25 = func.chama_treinamento_modelo(x_bm25_train,y_train, x_bm25_test,y_test, classificadorMLP, nomeAlgoritmoMLP,'BM25',param_grid_melhor_MLP, 1,n_cores_pequeno,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloMLP_BM25.getNome(),modeloMLP_BM25.getFeatureType(),modeloMLP_BM25.getMicroPrecision(),modeloMLP_BM25])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSI 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">> Fazendo Grid Search para classificador SVM\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging SVM para 712 elementos:  0:00:01.534390\n",
      ">> Testando classificador LSI100_SVM\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.091161\n",
      "Tempo para recuperar métricas:  0:00:00.038974\n",
      " \n",
      "Nome modelo: LSI100_SVM\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:00.409626\n",
      "Feature Type: LSI100\n",
      "Accuracy: 0.553072625698324\n",
      "Balanced Accuracy: 0.5545286100119339\n",
      "macro_precision 0.5503517144883369 \n",
      "macro_recall    0.5545286100119339 \n",
      "macro_fscore    0.5505291005291005\n",
      "micro_precision 0.5497867162396012 \n",
      "micro_recall    0.553072625698324 \n",
      "micro_fscore    0.5494945464219207\n",
      ">> Fazendo Grid Search para classificador Random Forest\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging Random Forest para 712 elementos:  0:00:10.602722\n",
      ">> Testando classificador LSI100_Random Forest\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.257999\n",
      "Tempo para recuperar métricas:  0:00:00.008202\n",
      " \n",
      "Nome modelo: LSI100_Random Forest\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:03.066634\n",
      "Feature Type: LSI100\n",
      "Accuracy: 0.5363128491620112\n",
      "Balanced Accuracy: 0.5380629357452421\n",
      "macro_precision 0.537950352554815 \n",
      "macro_recall    0.5380629357452421 \n",
      "macro_fscore    0.5349595919448861\n",
      "micro_precision 0.5375871943845926 \n",
      "micro_recall    0.5363128491620112 \n",
      "micro_fscore    0.533943099359629\n",
      ">> Fazendo Grid Search para classificador Multi-Layer Perceptron\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   2.9s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   3.3s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   2.1s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   1.9s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   2.1s\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging Multi-Layer Perceptron para 712 elementos:  0:00:14.319778\n",
      ">> Testando classificador LSI100_Multi-Layer Perceptron\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.006467\n",
      "Tempo para recuperar métricas:  0:00:00.007035\n",
      " \n",
      "Nome modelo: LSI100_Multi-Layer Perceptron\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:02.055586\n",
      "Feature Type: LSI100\n",
      "Accuracy: 0.5307262569832403\n",
      "Balanced Accuracy: 0.5322875447522141\n",
      "macro_precision 0.5275445573722197 \n",
      "macro_recall    0.5322875447522141 \n",
      "macro_fscore    0.5240601503759399\n",
      "micro_precision 0.5271577996282188 \n",
      "micro_recall    0.5307262569832403 \n",
      "micro_fscore    0.5229974377283992\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:    0.7s remaining:    0.5s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:    4.1s remaining:    2.7s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    7.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.3s finished\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "modeloSVM_LSI100 = func.chama_treinamento_modelo(x_lsi100_train,y_train, x_lsi100_test ,y_test, classificadorSVM,nomeAlgoritmoSVM, 'LSI100',param_grid_melhor_SVM, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloSVM_LSI100.getNome(),modeloSVM_LSI100.getFeatureType(),modeloSVM_LSI100.getMicroPrecision(),modeloSVM_LSI100])\n",
    "\n",
    "modeloRF_LSI100 = func.chama_treinamento_modelo(x_lsi100_train, y_train,x_lsi100_test ,y_test, classificadorRF,nomeAlgoritmoRF, 'LSI100',param_grid_melhor_RF, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloRF_LSI100.getNome(),modeloRF_LSI100.getFeatureType(),modeloRF_LSI100.getMicroPrecision(),modeloRF_LSI100])\n",
    "\n",
    "modeloMLP_LSI100 = func.chama_treinamento_modelo(x_lsi100_train,y_train, x_lsi100_test ,y_test, classificadorMLP, nomeAlgoritmoMLP,'LSI100',param_grid_melhor_MLP, 1,n_cores_pequeno,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloMLP_LSI100.getNome(),modeloMLP_LSI100.getFeatureType(),modeloMLP_LSI100.getMicroPrecision(),modeloMLP_LSI100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSI 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ">> Fazendo Grid Search para classificador SVM\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging SVM para 712 elementos:  0:00:01.785307\n",
      ">> Testando classificador LSI250_SVM\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.038621\n",
      "Tempo para recuperar métricas:  0:00:00.006254\n",
      " \n",
      "Nome modelo: LSI250_SVM\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:00.446137\n",
      "Feature Type: LSI250\n",
      "Accuracy: 0.547486033519553\n",
      "Balanced Accuracy: 0.5488819797751398\n",
      "macro_precision 0.5454833637654697 \n",
      "macro_recall    0.5488819797751398 \n",
      "macro_fscore    0.5458728789186081\n",
      "micro_precision 0.5450918404471994 \n",
      "micro_recall    0.547486033519553 \n",
      "micro_fscore    0.5449747181397949\n",
      ">> Fazendo Grid Search para classificador Random Forest\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging Random Forest para 712 elementos:  0:00:14.244062\n",
      ">> Testando classificador LSI250_Random Forest\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.228386\n",
      "Tempo para recuperar métricas:  0:00:00.007421\n",
      " \n",
      "Nome modelo: LSI250_Random Forest\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:04.760232\n",
      "Feature Type: LSI250\n",
      "Accuracy: 0.5307262569832403\n",
      "Balanced Accuracy: 0.5328811004333899\n",
      "macro_precision 0.5293535944080722 \n",
      "macro_recall    0.5328811004333899 \n",
      "macro_fscore    0.527966825395699\n",
      "micro_precision 0.528814428585947 \n",
      "micro_recall    0.5307262569832403 \n",
      "micro_fscore    0.5266648162442088\n",
      ">> Fazendo Grid Search para classificador Multi-Layer Perceptron\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   3.1s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   2.8s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   2.4s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   3.5s\n",
      "[CV] estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu \n",
      "[CV]  estimator__n_estimators=3, estimator__max_samples=0.8, estimator__base_estimator__solver=lbfgs, estimator__base_estimator__max_iter=300, estimator__base_estimator__learning_rate=invscaling, estimator__base_estimator__hidden_layer_sizes=(10, 10), estimator__base_estimator__alpha=0.001, estimator__base_estimator__activation=relu, total=   2.6s\n",
      "Tempo para execução do GridSearch para OVR Balanced Bagging Multi-Layer Perceptron para 712 elementos:  0:00:17.327374\n",
      ">> Testando classificador LSI250_Multi-Layer Perceptron\n",
      "Tempo para fazer a predicao de  179 elementos:  0:00:00.011136\n",
      "Tempo para recuperar métricas:  0:00:00.007602\n",
      " \n",
      "Nome modelo: LSI250_Multi-Layer Perceptron\n",
      "Quantidade de elementos de treinamento: 712\n",
      "Tempo de treinamento: 0:00:02.889322\n",
      "Feature Type: LSI250\n",
      "Accuracy: 0.5586592178770949\n",
      "Balanced Accuracy: 0.5582061428302242\n",
      "macro_precision 0.5584775349119612 \n",
      "macro_recall    0.5582061428302242 \n",
      "macro_fscore    0.5579121653949787\n",
      "micro_precision 0.5585040347610181 \n",
      "micro_recall    0.5586592178770949 \n",
      "micro_fscore    0.5581571969209381\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:    0.8s remaining:    0.6s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:    5.0s remaining:    3.4s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:    9.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   14.4s finished\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "modeloSVM_LSI250 = func.chama_treinamento_modelo(x_lsi250_train,y_train, x_lsi250_test ,y_test, classificadorSVM,nomeAlgoritmoSVM, 'LSI250',param_grid_melhor_SVM, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloSVM_LSI250.getNome(),modeloSVM_LSI250.getFeatureType(),modeloSVM_LSI250.getMicroPrecision(),modeloSVM_LSI250])\n",
    "\n",
    "modeloRF_LSI250 = func.chama_treinamento_modelo(x_lsi250_train, y_train,x_lsi250_test ,y_test, classificadorRF,nomeAlgoritmoRF, 'LSI250',param_grid_melhor_RF, 1,n_cores_grande,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloRF_LSI250.getNome(),modeloRF_LSI250.getFeatureType(),modeloRF_LSI250.getMicroPrecision(),modeloRF_LSI250])\n",
    "\n",
    "modeloMLP_LSI250 = func.chama_treinamento_modelo(x_lsi250_train,y_train, x_lsi250_test ,y_test, classificadorMLP, nomeAlgoritmoMLP,'LSI250',param_grid_melhor_MLP, 1,n_cores_pequeno,id_execucao ,data,path_resultados,df_resultados,nome_arquivo_destino,X_test)\n",
    "modelos.append([modeloMLP_LSI250.getNome(),modeloMLP_LSI250.getFeatureType(),modeloMLP_LSI250.getMicroPrecision(),modeloMLP_LSI250])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encontrando o modelo vencedor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "O modelo vencedor foi o TFIDF_Multi-Layer Perceptron, com 0.58 de micro precisão\n",
      "O modelo para transformação dos textos pré-processados se encontra no arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocsProcessados/MelhorModeloFeature.p e o modelo de classificação no arquivo /home/anarocha/Documents/DocumentosClassificadorAssuntos/DocsProcessados/MelhorModelo.p\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "modelos_df = pd.DataFrame(modelos, columns=['Nome Modelo','Feature Type','micro_precision','Modelo'])\n",
    "modelos_df= modelos_df.sort_values(by='micro_precision', ascending=False)\n",
    "print(\"O modelo vencedor foi o \" + modelos_df.iloc[0]['Nome Modelo'] + \", com \" + (str(\"%.2f\" % modelos_df.iloc[0]['micro_precision'])) + \" de micro precisão\")\n",
    "\n",
    "modelo_vencedor = modelos_df.iloc[0]['Modelo']\n",
    "\n",
    "arquivoPickle = open(path_resultados + \"MelhorModelo.p\", 'wb')\n",
    "pickle.dump(modelo_vencedor.getBestEstimator(), arquivoPickle)\n",
    "arquivoPickle.close()\n",
    "\n",
    "if modelo_vencedor.getFeatureType() == 'LSI100':\n",
    "    feature_vencedora = open(path_resultados + \"MelhorModeloFeature.p\", 'wb')\n",
    "    pickle.dump(lsi100_transformer, feature_vencedora)\n",
    "    feature_vencedora.close()\n",
    "elif modelo_vencedor.getFeatureType() == 'LSI250':\n",
    "    feature_vencedora = open(path_resultados + \"MelhorModeloFeature.p\", 'wb')\n",
    "    pickle.dump(lsi250_transformer, feature_vencedora)\n",
    "    feature_vencedora.close()\n",
    "elif modelo_vencedor.getFeatureType() == 'TFIDF':\n",
    "    feature_vencedora = open(path_resultados + \"MelhorModeloFeature.p\", 'wb')\n",
    "    pickle.dump(tfidf_transformer, feature_vencedora)\n",
    "    feature_vencedora.close()\n",
    "elif modelo_vencedor.getFeatureType() == 'BM25':\n",
    "    feature_vencedora = open(path_resultados + \"MelhorModeloFeature.p\", 'wb')\n",
    "    pickle.dump(bm25_transformer, feature_vencedora)\n",
    "    feature_vencedora.close()\n",
    "    \n",
    "print(\"O modelo para transformação dos textos pré-processados se encontra no arquivo \" + path_resultados + \"MelhorModeloFeature.p\" + \" e o modelo de classificação no arquivo \" + path_resultados + \"MelhorModelo.p\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}